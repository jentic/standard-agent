# Observability

Observability is **completely optional** and **opt-in**.  
If you donâ€™t install it, everything degrades gracefully to a no-op.  
If you do, you get **traces, metrics, and token usage** captured automaticallyâ€”framework-agnostic and exportable to your favorite OpenTelemetry backend.

---

## âœ¨ Why Use This?
- **Zero-risk opt-in** â†’ no dependencies? No problem. Your code still runs as-is.  
- **Open standards** â†’ powered by [OpenTelemetry](https://opentelemetry.io/), export anywhere (Langfuse, Jaeger, Honeycomb, etc).  
- **Composable exporters** â†’ add new backends with just a few lines of code.  
- **LLM-aware tracing** â†’ built-in token counting + aggregation across agent calls.  
- **Ergonomic API** â†’ decorate functions with `@observe` and youâ€™re done.

---

## ğŸš€ Quick Start

Install with observability extras:

```bash
pip install -e ".[observability]"
Initialize telemetry once in your entrypoint:

python
Copy code
from utils.observability import observe, setup_telemetry, TelemetryTarget

setup_telemetry(
    service_name="standard-agent",
    target=TelemetryTarget.LANGFUSE  # or TelemetryTarget.OTEL
)
Decorate functions and LLM calls:

python
Copy code
@observe
def compute(x, y):
    return x + y

@observe(llm=True)
def call_llm(messages):
    return llm.completion(messages)

@observe(root=True)
def solve(goal):
    ...
```

âœ… Thatâ€™s itâ€”your traces will flow to the configured backend.

## ğŸ—ï¸ Architecture
- utils/observability/observe.py â†’ @observe decorator (falls back to no-op if OTel isnâ€™t installed).
- utils/observability/otel_setup.py â†’ setup_telemetry(service_name, target) wires up the OTel SDK + exporter.
- utils/observability/exporters/ â†’ pluggable exporter factories:
  - langfuse.py â†’ uses LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, LANGFUSE_HOST. 
  - otel.py â†’ standard OTel env vars (OTEL_EXPORTER_OTLP_ENDPOINT, etc).

âš ï¸ If setup_telemetry is never called, spans are dropped silently. No config? No errors.


## ğŸ“Š Token Tracking

- @observe(llm=True) â†’ records prompt_tokens, completion_tokens, and total_tokens.
- @observe(root=True) â†’ aggregates tokens across all child calls into a single total_tokens attribute.
- Perfect for tracking LLM usage per run or per agent workflow.

## ğŸ”Œ Adding a New Exporter

1. Add create_\<name\>_exporter() in utils/observability/exporters/\<name\>.py.
2. Export it from utils/observability/exporters/__init__.py.
3. Add TelemetryTarget.<NAME> in otel_setup.py and dispatch in _create_exporter.


## ğŸ’¡ Contributing

Weâ€™d love your help!
Whether itâ€™s adding exporters, improving docs, or shaping better LLM observability, contributions are welcome.

ğŸ‘‰ Open an issue, submit a PR, or just share your ideas.